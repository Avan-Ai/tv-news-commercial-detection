{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🚀 شروع پیش‌پردازش...\n",
            "📄 Reading BBC.txt ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BBC.txt: 0it [00:00, ?it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "BBC.txt: 17720it [00:03, 4843.64it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📄 Reading CNN.txt ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CNN.txt: 22545it [00:05, 3984.38it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📄 Reading CNNIBN.txt ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "CNNIBN.txt: 33117it [00:06, 5084.30it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📄 Reading NDTV.txt ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "NDTV.txt: 17051it [00:03, 4900.15it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "📄 Reading TIMESNOW.txt ...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "TIMESNOW.txt: 39252it [00:10, 3692.89it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "🧹 حذف 3894 ویژگی با مقدار تکراری\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\niman\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:58:48] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ انتخاب 43 ویژگی مهم (براساس threshold = mean)\n",
            "➕ ویژگی‌های چندجمله‌ای اضافه شد: 55\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\niman\\anaconda3\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [20:58:54] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
            "Parameters: { \"use_label_encoder\" } are not used.\n",
            "\n",
            "  bst.update(dtrain, iteration=i, fobj=obj)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ انتخاب 26 ویژگی مهم (براساس threshold = mean)\n",
            "✅ پیش‌پردازش کامل شد.\n",
            "📊 شکل نهایی داده: (129685, 27)\n",
            "📁 فایل نهایی ذخیره شد: FinalPreProcessing.csv\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from sklearn.feature_selection import SelectFromModel\n",
        "from xgboost import XGBClassifier\n",
        "\n",
        "# مسیر فایل‌ها\n",
        "DATA_DIR = '../data'\n",
        "FEATURE_COUNT = 4125\n",
        "\n",
        "# ------------------------------------\n",
        "# تبدیل داده‌های LibSVM به DataFrame\n",
        "# ------------------------------------\n",
        "def parse_libsvm_line(line):\n",
        "    parts = line.strip().split()\n",
        "    label = int(parts[0].replace('+', ''))\n",
        "    features = [0.0] * FEATURE_COUNT\n",
        "    for item in parts[1:]:\n",
        "        index, value = item.split(\":\")\n",
        "        index = int(index)\n",
        "        if 1 <= index <= FEATURE_COUNT:\n",
        "            features[index - 1] = float(value)\n",
        "    return [label] + features\n",
        "\n",
        "def load_all_data():\n",
        "    data = []\n",
        "    for filename in os.listdir(DATA_DIR):\n",
        "        if filename.endswith(\".txt\"):\n",
        "            filepath = os.path.join(DATA_DIR, filename)\n",
        "            print(f\"📄 Reading {filename} ...\")\n",
        "            with open(filepath, \"r\") as file:\n",
        "                for line in tqdm(file, desc=filename):\n",
        "                    row = parse_libsvm_line(line)\n",
        "                    data.append(row)\n",
        "    columns = ['label'] + [f'feature_{i}' for i in range(1, FEATURE_COUNT + 1)]\n",
        "    df = pd.DataFrame(data, columns=columns)\n",
        "    return df\n",
        "\n",
        "# ------------------------------------\n",
        "# حذف ویژگی‌های با مقدار تکراری\n",
        "# ------------------------------------\n",
        "def remove_single_value_columns(df):\n",
        "    cols_to_drop = [col for col in df.columns if df[col].nunique() == 1]\n",
        "    print(f\"🧹 حذف {len(cols_to_drop)} ویژگی با مقدار تکراری\")\n",
        "    return df.drop(columns=cols_to_drop)\n",
        "\n",
        "# ------------------------------------\n",
        "# نرمال‌سازی داده‌ها\n",
        "# ------------------------------------\n",
        "def normalize(df):\n",
        "    X = df.drop(columns=['label'])\n",
        "    y = df['label']\n",
        "    scaler = StandardScaler()\n",
        "    X_scaled = scaler.fit_transform(X)\n",
        "    X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)\n",
        "    return pd.concat([y.reset_index(drop=True), X_scaled_df], axis=1)\n",
        "\n",
        "# ------------------------------------\n",
        "# حذف داده‌های پرت\n",
        "# ------------------------------------\n",
        "def replace_outliers_with_mean(df):\n",
        "    labels = df['label']\n",
        "    features = df.drop(columns=['label'])\n",
        "    cleaned = features.copy()\n",
        "    for col in cleaned.columns:\n",
        "        Q1 = cleaned[col].quantile(0.25)\n",
        "        Q3 = cleaned[col].quantile(0.75)\n",
        "        IQR = Q3 - Q1\n",
        "        lower = Q1 - 1.5 * IQR\n",
        "        upper = Q3 + 1.5 * IQR\n",
        "        outliers = cleaned[(cleaned[col] < lower) | (cleaned[col] > upper)][col]\n",
        "        if len(outliers) > 0:\n",
        "            if len(outliers) > 1000:\n",
        "                distances = np.maximum(outliers - upper, lower - outliers)\n",
        "                top_outliers = distances.abs().sort_values(ascending=False).head(1000).index\n",
        "            else:\n",
        "                top_outliers = outliers.index\n",
        "            mean_val = cleaned[(cleaned[col] >= lower) & (cleaned[col] <= upper)][col].mean()\n",
        "            cleaned.loc[top_outliers, col] = mean_val\n",
        "    cleaned['label'] = labels\n",
        "    return cleaned\n",
        "\n",
        "# ------------------------------------\n",
        "# انتخاب ویژگی‌های مهم با XGBoost\n",
        "# ------------------------------------\n",
        "def select_important_features(X, y, threshold=\"mean\"):\n",
        "    try:\n",
        "        y = np.array(y)\n",
        "        y = np.where(y == -1, 0, y)\n",
        "        if isinstance(X, pd.DataFrame):\n",
        "            feature_names = X.columns\n",
        "            X = X.select_dtypes(include=[np.number])\n",
        "            X_array = X.values\n",
        "        else:\n",
        "            X_array = X\n",
        "            feature_names = [f'feature_{i}' for i in range(X_array.shape[1])]\n",
        "        model = XGBClassifier(n_estimators=100, random_state=42, n_jobs=-1, use_label_encoder=False, eval_metric='logloss')\n",
        "        model.fit(X_array, y)\n",
        "        selector = SelectFromModel(model, threshold=threshold, prefit=True)\n",
        "        X_selected_array = selector.transform(X_array)\n",
        "        if X_selected_array.shape[1] == 0:\n",
        "            print(\"⚠️ هیچ ویژگی‌ای انتخاب نشد. بازگشت به ورودی اولیه.\")\n",
        "            return pd.DataFrame(X_array, columns=feature_names), y\n",
        "        selected_cols = [col for col, keep in zip(feature_names, selector.get_support()) if keep]\n",
        "        X_selected_df = pd.DataFrame(X_selected_array, columns=selected_cols)\n",
        "        print(f\"✅ انتخاب {len(selected_cols)} ویژگی مهم (براساس threshold = {threshold})\")\n",
        "        return X_selected_df, y\n",
        "    except Exception as e:\n",
        "        print(f\"❌ خطا در انتخاب ویژگی‌ها: {e}\")\n",
        "        return pd.DataFrame(X_array, columns=feature_names), y\n",
        "\n",
        "# ------------------------------------\n",
        "# تولید ویژگی‌های چند جمله‌ای\n",
        "# ------------------------------------\n",
        "def add_polynomial_features(X, degree=2):\n",
        "    try:\n",
        "        top_features = X.iloc[:, :10]\n",
        "        poly = PolynomialFeatures(degree=degree, interaction_only=True, include_bias=False)\n",
        "        X_poly = poly.fit_transform(top_features)\n",
        "        poly_feature_names = poly.get_feature_names_out(top_features.columns)\n",
        "        df_poly = pd.DataFrame(X_poly, columns=poly_feature_names, index=X.index)\n",
        "        print(f\"➕ ویژگی‌های چندجمله‌ای اضافه شد: {df_poly.shape[1]}\")\n",
        "        return pd.concat([X, df_poly], axis=1)\n",
        "    except Exception as e:\n",
        "        print(f\"❌ خطا در تولید ویژگی‌های چندجمله‌ای: {e}\")\n",
        "        return X\n",
        "\n",
        "# ------------------------------------\n",
        "# اجرای کامل پیش‌پردازش\n",
        "# ------------------------------------\n",
        "def full_preprocessing_pipeline():\n",
        "    print(\"🚀 شروع پیش‌پردازش...\")\n",
        "    df = load_all_data()\n",
        "    df = remove_single_value_columns(df)\n",
        "    df = normalize(df)\n",
        "    df = replace_outliers_with_mean(df)\n",
        "\n",
        "    X = df.drop(columns=['label'])\n",
        "    y = df['label']\n",
        "\n",
        "    # انتخاب ویژگی مهم اولیه\n",
        "    X_selected, y = select_important_features(X, y, threshold=\"mean\")\n",
        "\n",
        "    # افزودن ویژگی‌های چند جمله‌ای\n",
        "    X_extended = add_polynomial_features(X_selected)\n",
        "\n",
        "    # انتخاب مجدد ویژگی‌های مهم\n",
        "    X_final, y = select_important_features(X_extended, y, threshold=\"mean\")\n",
        "\n",
        "    final_df = pd.concat([X_final, pd.Series(y, name='label')], axis=1)\n",
        "    print(\"✅ پیش‌پردازش کامل شد.\")\n",
        "    print(f\"📊 شکل نهایی داده: {final_df.shape}\")\n",
        "    return final_df\n",
        "\n",
        "# ------------------------------------\n",
        "# اجرای برنامه\n",
        "# ------------------------------------\n",
        "if __name__ == '__main__':\n",
        "    final_df = full_preprocessing_pipeline()\n",
        "final_df.to_csv(\"../data/FinalPreProcessing.csv\", index=False)\n",
        "print(\"📁 فایل نهایی ذخیره شد: FinalPreProcessing.csv\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
